Starting code feedback for Xuan, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 18.40 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: .git, MiniProject, Week7, Week1, Week3, Feedback, Week2, xw1722

Found the following files in parent directory: .DS_Store, README.md, .gitignore

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
.DS_Store
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# CMEE Coursework Repository

## Description:

This is the repository of the coursework for MSc in Computational Methods in Ecology and Evolution, Imperial College London Silwood Campus, for the academic year 2022/23.

The CourseWork in this repository is mainly composed of the contents in *The Multilingual Quantitative Biologist* from the link: https://mhasoba.github.io/TheMulQuaBio/intro.html

The major source of the dataset are from:
git@github.com:mhasoba/TheMulQuaBio.git

## Structure:

The contents in each directory are listed as follows.

### Week1:

Week1 is an introduction to the Unix & Linux system.

- Shell scripting

- LaTeX learning

### Week2:

This directory contains mainly the instructions to Python programming, which includes:

- Loops and list comprehensions

- Writing a program with control flows

- Unit testing with docstring

- Some commonly used Python packages

### Week3:

Week3 mainly focus on the R scripting.

- R basics

- R control flows

- Vectorization

- Debugging

### Week7:

Week7 contains some advanced skills in Python, and also an introduction to Jupyter Notebook.

- Numerical computing

- Profiling

- Using Python to build workflows

### xw1722:

This is the HPC directory containing the High Performance Computing Programming Exercises. The files inside includes:

- xw1722_HPC_2022_neutral_cluster.R: The R script used for clustering for the neutral model;

- xw1722_HPC_2022_demographic_cluster.R: The R script used for clustering for the stochastic model;

- xw1722_HPC_2022_main.R: The R script containing the answers to all the questions from 1 to 37, and also the challenge questions;

- .png files: The graphs generated from the answers;

- .e and .o files: Generated by the cluster for the simulation runs;

- .rda files: Output files generated from the simulation runs, and a summary file.

### MiniProject:

The files in the directory of MiniProject provides the answers to the question: *What mathematical models best fit an empirical dataset?*

## Dependencies:

**Languages:**

R version 4.2.2

Python 3.9.12

IPython 7.31.1

LaTeX

Shell

**Packages:**

*Python* - numpy, scipy, matplotlib, ipdb, pandas

*R* - minpack.lm, tidyverse, reshape2, maps

## Author name and contact:

Author: Xuan Wang

Email: xuan.wang22@imperial.ac.uk

**********************************************************************

======================================================================
Looking for the weekly directories...

Found 4 weekly directories: Week1, Week2, Week3, Week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: code, results, data

Found the following files: README.md, .gitignore

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# CMEE Coursework Week3


## Description:

This is the homework for week3 of CMEE. The work includes seven tasks. This was completed and pushed on 4th Nov 2022, and modifications are made on 15 Dec 2022.


## Language:

R, LaTeX


## Structure:

**Individual Work**

*TreeHeight.R* - Loads *trees.csv* and calculate tree heights in the data;

*Vectorize2.R* - Vectorisation challenge

*Florida.R, Florida.tex, Florida.pdf* - Florida getting warmer

*DataWrangTidy.R* - Data wrangling with package *tidyverse*

*PP_Dists.R* - Body mass distributions

*PP_Regress.R* - Visualizing regression analyses

*GPDD_Data.R* - Mapping

**Group Work**

*FloridaYears.tex*

*get_TreeHeight.py*

*get_TreeHeight.R*

*PP_regress_loc.R*

*run_get_TreeHeight.sh*

*TAutoCorr.R*

## Packages installation

To run the script *GPDD_Data.R*, the *maps* package is needed. Run the following code in R to install the package:

install.packages(c("maps", "tidyverse"))


## Author name and contact:

Xuan Wang

xuan.wang22@imperial.ac.uk
**********************************************************************

Results directory is empty - good! 

Found 33 code files: apply2.R, apply1.R, Girko.R, next.R, plotLin.R, Florida.R, sample.R, PP_Dists.R, get_TreeHeight.py, SQLinR.R, try.R, PP_regress_loc.R, FloridaYears.tex, MyBars.R, control_flow.R, TAutoCorr.R, Ricker.R, boilerplate.R, R_conditionals.R, browse.R, GPDD_Data.R, PP_Regress.R, get_TreeHeight.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, break.R, run_get_TreeHeight.sh, DataWrang.R, Florida.tex, TreeHeight.R, basic_io.R, Vectorize1.R

Found the following extra files: Test.sqlite, Florida.pdf, Rplots.pdf
0.5 pt deducted per extra file

Current Points = 98.5

======================================================================
Testing script/code files...

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
SomeOperation <- function(v) {
    if (sum(v) > 0) {
        return (v * 100)
    } else {
        return (v)
    }
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************
            [,1]       [,2]       [,3]        [,4]       [,5]       [,6]
 [1,]  1.1247057   84.08490 -0.8055957 -0.07098621 -1.1533627 158.296853
 [2,] -0.7463805 -103.30539  0.1729833 -0.21769725  1.1683360 -86.205848
 [3,] -0.3985233   64.22148  0.4575903 -0.44789250 -0.7228626 -34.573812
 [4,] -0.2604252  -47.75600  1.2308154 -0.76512769  0.3720718  -1.718823
 [5,] -1.5856553 -151.24554  0.3716829  0.37195832  0.3085550 -35.686495
 [6,]  0.2339458   58.42798 -0.2972792  0.38631515 -0.4229290  
**********************************************************************

Code ran without errors

Time consumed = 0.19799s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
## Build a random matrix
M <- matrix(rnorm(100),10,10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

# Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

#By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)
**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1] -0.03009999  0.21279294  0.42892310 -0.86934961 -0.13110266  0.17148580
 [7]  0.13663333  0.21179094  0.25478320 -0.64103110
 [1] 0.7320550 1.9141960 0.7429575 0.7258881 0.6383685 0.5536359 0.8585403
 [8] 0.3771252 1.2949068 0.7681820
 [1]  0.42741389 -0.13420646 -0.06493912 -0.64332234 -0.16348946  0.04714132
 [7]  0.06935388  0.07239006  0.06706836  0.06741582

**********************************************************************

Code ran without errors

Time consumed = 0.18519s

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************

require(ggplot2)

build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
pdf("../results/Girko.pdf")
p = ggplot(eigDF, aes(x = Real, y = Imaginary))
p = p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")
# now add the vertical and horizontal line
p = p + geom_hline(aes(yintercept = 0))
p = p + geom_vline(aes(xintercept = 0))
# finally, add the ellipse
p = p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
print(p)
graphics.off();
**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************
for (i in 1:10) {
    if ((i %% 2) == 0)
      next # pass to next iteration of loop
    print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.20144s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************
require(ggplot2)
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
pdf("../results/MyLinReg.pdf", width = 11, height = 8)
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))
# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")
print(p)
graphics.off();

**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file Florida.R...

File contents are:

**********************************************************************
rm(list = ls())
load("../data/KeyWestAnnualMeanTemperature.RData")

# calculating the correlation coefficient between years and temperature
corrcoeff <- cor(ats$Year, ats$Temp)

# repeating the calculation, each time randomly reshuffling the temperatures
set.seed(1)
randcorr <- c()
for (i in 1:100) {
    randcorr[i] <- cor(ats$Year, sample(ats$Temp, replace = FALSE))
}


# calculating the fraction of greater correlation coefficients
i <- 0
for (j in randcorr){
    if (j > corrcoeff){
        i <- i + 1
    }
}
p_value <- i/100

# plotting graphs and save the results
pdf("../data/Floridaplot.pdf")
hist(randcorr, xlab = "Correlation coefficients", ylab = "Frequency",
        main = "The frequency of coefficients between years and temperature",
        xlim = c(-0.6,0.6))
abline(v = corrcoeff, col = "red")
text(0.4, 10, paste("original correlation coefficient", corrcoeff),
    col = "red", cex = 0.7)
text(0.4, 5, "p-value: 0")
graphics.off()


**********************************************************************

Testing Florida.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.23762s

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}

## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}

## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}

set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)

n <- 100 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment

print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))

print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))

print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))

print("Using the vectorized sapply function (on a list) took:" )
print(system.time(sapply_sample(popn, n, num)))

print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))
**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops without preallocation on a vector took:"
   user  system elapsed 
  0.345   0.015   0.361 
[1] "Using loops with preallocation on a vector took:"
   user  system elapsed 
  0.221   0.000   0.221 
[1] "Using loops with preallocation on a list took:"
   user  system elapsed 
  0.222   0.000   0.221 
[1] "Using the vectorized sapply function (on a list) took:"
   user  system elapsed 
  0.226   0.000   0.226 
[1] "Using the vectorized lapply function (on a list) took:"
   user  syst
**********************************************************************

Code ran without errors

Time consumed = 1.57870s

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
# loading data
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# loading packages
require(ggplot2)
require(tidyverse)
require(dplyr)

# factorising certain columns
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)
str(MyDF)
category <- unique(MyDF$Type.of.feeding.interaction)
length(category)

# computing the size ratio of prey mass over predator mass by feeding interaction type
ratio <- function(prey, predator){
    result <- prey/predator
    return(result)
}

MyDF$ratio <- ratio(MyDF$Prey.mass, MyDF$Predator.mass)

# pred subplots
pdf("../results/Pred_Subplots.pdf", width = 11, height = 8)
n = 1
par(mfrow = c(5, 1))
mean_pred = c()
median_pred = c()
for (each in category){
    par(mfg = c(n, 1))
    plot(density(log10(MyDF$Predator.mass[MyDF$Type.of.feeding.interaction == each])), 
        xlab = "log10(Pred Mass)",
        ylab = "Density",
        main = each)
    mean_pred <- c(mean_pred, log(mean(MyDF$Predator.mass[MyDF$Type.of.feeding.interaction == each])))
    median_pred <- c(median_pred, median(MyDF$Predator.mass[MyDF$Type.of.feeding.interaction == each]))
    n <- n + 1
}
graphics.off();

# prey subplots
pdf("../results/Prey_Subplots.pdf", width = 11, height = 8)
m = 1
par(mfrow = c(5, 1))
mean_prey = c()
median_prey = c()
for (each in category){
    par(mfg = c(m, 1))
    plot(density(log10(MyDF$Prey.mass[MyDF$Type.of.feeding.interaction == each])),
        xlab = "log10(Prey Mass)",
        ylab = "Density",
        main = each)
    mean_prey <- c(mean_prey, log(mean(MyDF$Prey.mass[MyDF$Type.of.feeding.interaction == each])))
    median_prey <- c(median_prey, median(MyDF$Prey.mass[MyDF$Type.of.feeding.interaction == each]))
    m <- m + 1
}
graphics.off();

# size ratio subplots
pdf("../results/SizeRatio_Subplots.pdf", width = 11, height = 8)
g = 1
par(mfrow = c(5, 1))
mean_ratio = c()
median_ratio = c()
for (each in category){
    par(mfg = c(g, 1))
    plot(density(log10(MyDF$ratio[MyDF$Type.of.feeding.interaction == each])),
        xlab = "log10(Size ratio of prey mass over predator mass)",
        main = each)
    mean_ratio <- c(mean_ratio, log(mean(MyDF$ratio[MyDF$Type.of.feeding.interaction == each])))
    median_ratio <- c(median_ratio, median(MyDF$ratio[MyDF$Type.of.feeding.interaction == each]))
    g <- g + 1
}
graphics.off();

# creating the dataframe
df <- data.frame(category, mean_pred, mean_prey, mean_ratio, median_pred, median_prey, median_ratio)
write.csv(df, "../results/PP_results.csv")
**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************
'data.frame':	34931 obs. of  15 variables:
 $ Record.number              : int  1 2 3 4 5 6 7 8 9 10 ...
 $ In.refID                   : chr  "ATSH063" "ATSH080" "ATSH089" "ATSH143" ...
 $ IndividualID               : chr  "1" "2" "3" "4" ...
 $ Predator                   : chr  "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" "Rhizoprionodon terraenovae" ...
 $ Predator.common.name       : chr  "Atlantic sharpnose shark" "Atlantic sharpnose shark" "Atlantic 
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
✔ purrr   0.3.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:

**********************************************************************
"""
Description:
This is the script for the week3 Groupwork on Tree Heights.

Required package for this script:
sys - used for taking argument from the command line
os - used for the elimination of extension from the input name when saving the output file
pandas - used to read the dataset
numpy - used for the mathematical computation

Date:
11 Dec 2022
"""

__author__ = "Xuan Wang xuan.wang22@imperial.ac.uk"
__appname__ = "get_TreeHeight.py"
__package__ = "sys, os, pandas, numpy"

# importing the required package
import sys
import os
import pandas as pd
import numpy as np

# taking the argument from command line
argv = str(sys.argv[1])

# loading dataset
path = ["../data/",argv]
treedata = pd.read_csv("".join(path))
# tree height definition
def TreeHeight(degrees, distance):
    """
    This function defines the function of tree height.
    """
    radians = degrees * np.pi / 180
    height = distance * np.tan(radians)
    return height

# adding the column of tree height to the data
treedata["Tree.Height.m"] = TreeHeight(treedata["Angle.degrees"], treedata["Distance.m"])

# select the first two rows of data
treedata = treedata.head(2)
treedata["Input_Name"] = argv

# saving the output file
path_results = ["../results/",os.path.splitext(argv)[0],"_treeheights.csv"]
treedata.to_csv("".join(path_results))


**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 98.5

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Traceback (most recent call last):
  File "/home/mhasoba/Documents/Teaching/IC_CMEE/2022-23/Coursework/StudentRepos/XuanWang_/Week3/code/get_TreeHeight.py", line 26, in <module>
    argv = str(sys.argv[1])
IndexError: list index out of range

======================================================================
Inspecting script file SQLinR.R...

File contents are:

**********************************************************************
#install the sqlite package
install.packages("sqldf")

# To load the packages
library(sqldf)

# The command below opens a connection to the database.
#If the database does not yet exist, one is created in the working directory of R.
db <- dbConnect(SQLite(), dbname='Test.sqlite')

# Now let's enter some data to the table
# Using the db connection to our database, the data are entered using SQL queries
# The next command just create the table
dbSendQuery(conn = db,
            "CREATE TABLE Consumer
       (OriginalID TEXT,
        ConKingdom TEXT,
        ConPhylum TEXT,
        ConSpecies TEXT)")

# Once the table is created, we can enter the data.
#INSERT specifies where the data is entered (here the School table).
#VALUES contains the data

 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (1, 'Animalia', 'Arthropoda', 'Chaoborus trivittatus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (2, 'Animalia', 'Arthropoda', 'Chaoborus americanus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (3, 'Animalia', 'Chordata', 'Stizostedion vitreum')")


# Once we have our table, we can query the results using:

dbGetQuery(db, "SELECT * FROM Consumer")
dbGetQuery(db, "SELECT * FROM Consumer WHERE ConPhylum='Chordata'")


# Tables can be also imported from csv files.
# As example, let's use the Biotraits dataset.
# The easiest way is to read the csv files into R as data frames.
# Then the data frames are imported into the database.

Resource <- read.csv("../Data/Resource.csv")  # Read csv files into R

# Import data frames into database
 dbWriteTable(conn = db, name = "Resource", value = Resource, row.names = FALSE)

# Check that the data have been correctly imported into the School table.
 dbListTables(db)                 # The tables in the database
 dbListFields(db,"Resource")       # The columns in a table
 dbReadTable(db, "Resource")    # The data in a table

# Before leaving RSQLite, there is a bit of tidying-up to do.
# The connection to the database is closed, and as precaution
# the three data frames are removed from R’s environment.
 dbDisconnect(db)            # Close connection
 rm(list = c("Resource"))   # Remove data frames



**********************************************************************

Testing SQLinR.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
Warning in install.packages("sqldf") :
  'lib = "/usr/local/lib/R/site-library"' is not writable
Error in install.packages("sqldf") : unable to install packages
Execution halted

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************
doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
        } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }

set.seed(1345) # again, to get the same result for illustration

popn <- rnorm(50)

hist(popn)

# store the errors in result by using "try"
result <- lapply(1:15, function(i) try(doit(popn), TRUE))

# manual approach
result <- vector("list", 15) #Preallocate/Initialize
for(i in 1:15) {
    result[[i]] <- try(doit(popn), TRUE)
    }
**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: -0.11620822588674"
[1] "Mean of this sample was: -0.0468516755995931"
[1] "Mean of this sample was: -0.0890228211466614"
[1] "Mean of this sample was: -0.124229742255296"
[1] "Mean of this sample was: 0.0314144452816157"
[1] "Mean of this sample was: -0.233476945796405"
[1] "Mean of this sample was: -0.196681538928001"
[1] "Mean of this sample was: 0.0146969612111605"
[1] "Mean of this sample was: -0.234913159471725"
[1] "Mean of this sample was: -0.0497464588165691"
**********************************************************************

Code ran without errors

Time consumed = 0.23626s

======================================================================
Inspecting script file PP_regress_loc.R...

File contents are:

**********************************************************************
# Cleaning the environment
rm(list = ls())

# Loading the required packages
library(tidyverse)

# Loading the data as MyDF
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# Converting the Prey mass to grams 
MyDF$Prey.mass[MyDF$Prey.mass.unit == 'mg'] <- 
    MyDF$Prey.mass[MyDF$Prey.mass.unit == 'mg']/1000

# Creating a dataframe of required columns only
new <- MyDF %>% select(Prey.mass, Predator.mass, 
                       Type.of.feeding.interaction, Predator.lifestage,
                       Location)

# Creating an empty data frame
new_df <- data.frame(Type.of.feeding.interaction = character(),
                     Predator.lifestage = character(),
                     Location = character(),
                     Regression.slope = double(), 
                     Regression.intercept = double(), 
                     R.squared = double(), 
                     F.statistic = double(),
                     p.value = double())

# Fitting linear regressions subset-wise and saving the required values to the 
# initialized dataframe

for(inter in unique(new$Type.of.feeding.interaction)){
    for(lifestage in unique(new$Predator.lifestage)){
        for(loc in unique(new$Location)){
            tmp <- new %>%
                filter(Type.of.feeding.interaction == inter,
                       Predator.lifestage == lifestage,
                       Location == loc)
            if(nrow(tmp) > 2){ # Only fitting regression if there are more than 2 observations
                mod <- lm(log10(Predator.mass)~log10(Prey.mass), data = tmp)
                tmp1 <- summary(mod)
                needed <- c(tmp1$coefficients[2,1],
                            tmp1$coefficients[1,1],
                            tmp1$adj.r.squared, 
                            tmp1$fstatistic[1], 
                            tmp1$coefficients[,4][2])
                new_df[nrow(new_df)+1,] <- c(inter, lifestage, loc, needed)
            }
        }
    }
}


# Writing the data frame to a results file
write.csv(new_df, file = '../results/PP_Regress_Results.csv', row.names = F)

**********************************************************************

Testing PP_regress_loc.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Warning messages:
1: In summary.lm(mod) : essentially perfect fit: summary may be unreliable
2: In summary.lm(mod) : essentially perfect fit: summary may be unreliable

======================================================================
Inspecting script file FloridaYears.tex...

File contents are:

**********************************************************************
\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Are temperatures of one year significantly correlated with the next year (successive years), across years in a given location?}
\author{CMEE Group 3 }
\date{December 2022}

\begin{document}

\maketitle

\section{Introduction}
There is significant evidence to assume that the temperature of Florida has been increasing over the years 1901 - 2000, and we wish to determine whether there is also a significant correlation between temperature over the successive years themselves.

\section{Method}
Under the assumption that temperature, the dependant variable is normally distributed, a  two tailed t-test was performed to determine an estimation for the correlation between temperatures across successive years. 

Since observations of the dependent variable (time) are not independent of each-other, a 2 tailed hypothesis test was performed with significance level $\alpha = 0.01$ and with the following null ($H_0$) and alternative ($H_A$) hypotheses, where $r$ is the true correlation, and $r_{observed}$ is the correlation observed within the data.
 \[ H_0: | r | <  r_{observed}\]
    \[H_A: |r| \geq r_{observed} \]

The measurements of temperature were permuted and assigned to years randomly for 10 000 trials. For each trial a paired sample t-test was performed on the newly generated data points and the corresponding correlation was recorded. This calculation was then compared with the correlation calculated for the true data, to investigate how likely a correlation as strong as the one observed is to occur within meaningless data.


\section{Results}
The paired sample t-test performed on the first 99 years and their successive years gave an estimated correlation of 0.3261697.

The correlations calculated for the randomly assigned temperature measurements were greater than 0.3261697 (or less than -0.3261697) for only 0.079\% of the trials. This gives an estimated p-value of 0.00079, which is substantially smaller than the significance level $\alpha$.

Therefore, we can reject $H_0$ and conclude that at a 1\% significance level, the data provides significant evidence that the temperature of Florida is positively correlated across successive years.

\end{document}

**********************************************************************

Testing FloridaYears.tex...

======================================================================
Inspecting script file MyBars.R...

File contents are:

**********************************************************************
require(ggplot2)
a <- read.table("../data/Results.txt", header = TRUE)
head(a)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
pdf("../results/MyBars.pdf", width = 11, height = 8)
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 
print(p)
dev.off()
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 


**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>
null device 
          1 

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
a <- TRUE
if (a == TRUE){
    print ("A is TRUE")
} else {
    print ("a is FALSE")
}

z <- runif(1)
if (z<=0.5) {
    print ("Less than a half")
}

for (i in 1:10) {
    j <- i * i
    print(paste(i, " squared is", j ))
}

for (species in c('Heliodoxa rubinoides', 'Boissonneaua jardini', 'Sula nebouxii')){
    print(paste('The species is', species))
}

v1 <- c("a", "bc", "def")
for (i in v1){
    print(i)
}

i <- 0
while (i < 10){
    i <- i + 1
    print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "A is TRUE"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.21810s

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
## TAutoCorr.R ##
load("../data/KeyWestAnnualMeanTemperature.RData")


df <- data.frame(ats$Temp[1:99], ats$Temp[2:100])
names(df) <- c("Temp", "Successive Temp")
 
# paired t-test
cor.test(df$Temp, df$`Successive Temp`)

## randomly permute time series ##


n <- 100000                 #number of trials
random_successes <- 0       #count of randomly generated correlations which are stronger than test statistic
success_list <- list()      #list random successes

for (i in 1:n){
  new_tempseries <- sample(ats$Temp, 100, replace = F)        #permutes temperature measurements
  new_DF <- data.frame(new_tempseries[1:99], new_tempseries[2:100])                 #forms new data frame of first 99 years and their successive years
  correlation <- as.numeric(cor.test(new_DF[[1]], new_DF[[2]])['estimate'])         #determines correlation
  if ( abs(correlation) >= cor.test(df$Temp, df$`Successive Temp`)['estimate'])  {  #counts and stores correlation if stronger than correlation observed for true data
    random_successes = random_successes + 1
    success_list <- append(success_list, correlation)
  }
}

#find percentage
rate = random_successes / n
print(rate)

#differenciate between negative and positive correlations
length(success_list[success_list < 0])
length(success_list[success_list > 0])
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************

	Pearson's product-moment correlation

data:  df$Temp and df$`Successive Temp`
t = 3.3982, df = 97, p-value = 0.0009852
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.1376191 0.4919077
sample estimates:
      cor 
0.3261697 


**********************************************************************

Code ran without errors

Time consumed = 10.00546s

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

plot(Ricker(generations=10), type="l")
**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.23132s

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# A boilerplate R script

MyFunction <- function(Arg1, Arg2) {
    print(paste("Argument", as.character(Arg1), "is a", class(Arg1)))
    print(paste("Argument", as.character(Arg2), "is a", class(Arg2)))

    return (c(Arg1, Arg2))
}

MyFunction(1,2)
MyFunction("Riki", "Tiki")

**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.21402s

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************

is.even <- function( n = 2 ) {
    if (n %% 2 == 0) {
        return(paste(n, 'is even!'))
    } else {
        return(paste(n,'is odd!'))
    }
}
is.even(6)

is.power2 <- function(n = 2){
    if (log2(n) %% 1 == 0) {
        return(paste(n, 'is a power of 2!'))
    } else {
        return(paste(n,'is not a power of 2!'))
    }
}
is.power2(4)

is.prime <- function(n){
    if (n == 0) {
        return(paste(n, 'is a zero!'))
    } else if (n == 1) {
        return(paste(n,'is just a unit'))
    }

    ints <- 2:(n-1)

    if (all(n%%ints != 0)){
        return(paste(n, 'is a prime'))
    } else {
        return(paste(n, 'is a composite!'))
    }
}

is.prime(3)
**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is even!"
[1] "4 is a power of 2!"
[1] "3 is a prime"

**********************************************************************

Code ran without errors

Time consumed = 0.18522s

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.23126s

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
# loading the mapping package
require(maps)

# loading the GPDD data
mapdata <- get(load("../data/GPDDFiltered.RData"))

# creating a world map
mymap <- map(database = "world")

# superimpose the locations from the data
points(x = mapdata$lat, y = mapdata$long, col = rainbow(200), pch = 20)

#########################
#########################

# From the map driven, it is observed that the data is gathered around the east
# coast of Africa, while few data is obtained from the Atlantic Ocean and the
# Southern Ocean. Since the location of data source is not random enough, the
# results driven may not be representative for species worldwide, which could
# lead to a bias in analysis.
# Meanwhile, it is possible for researchers to use the data from Atlantic Ocean
# and Southern Ocean as representative for these area. However, due to the
# limited number of data, it could also cause bias by the comparatively small
# sample size.
 
#########################
**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: maps

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
# loading the dataset and package
require(ggplot2)
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

# factorize
MyDF$Predator.lifestage <- as.factor(MyDF$Predator.lifestage)
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)

# plotting the graph
pdf("../results/PP_Regress.pdf")
print(ggplot(MyDF, aes(x = log(Prey.mass), y = log(Predator.mass),
                        colour = Predator.lifestage)) +
        geom_point(shape = I(3)) +
        theme_bw() +
        geom_smooth(method = "lm", fullrange = TRUE, size = 0.5) +
        facet_wrap(Type.of.feeding.interaction ~., ncol = 1) +
        labs(x = "Prey Mass in grams", y = "Predator mass in grams") +
        theme(legend.position = "bottom", aspect.ratio = 0.3) +
        guides(colour=guide_legend(nrow = 1)))
graphics.off();

# computation of regression results
# initialising
reg.slope <- c()
reg.intercept <- c()
r.squared <- c()
f.statistics <- c()
p.value <- c()
results <- data.frame()

lifestage <- unique(MyDF$Predator.lifestage)

for(l in lifestage){
    # dataset for each lifestage
    stage = subset(MyDF, Predator.lifestage == l)

    for(t in unique(stage$Type.of.feeding.interaction)){
        # dataset for each type of feeding interaction
        type = subset(stage, Type.of.feeding.interaction == t)
        lm_summary <- summary(lm(log(Predator.mass)~log(Prey.mass), data = type))
        
        if(is.null(lm_summary$fstatistic[1])){
            f.statistics = c(f.statistics, "NA")
        } else {
            f.statistics = c(f.statistics, as.numeric(lm_summary$fstatistic[1]))
            }
        
        reg.slope <- c(reg.slope, lm_summary$coefficients[2])
        reg.intercept = c(reg.intercept, lm_summary$coefficients[1])
        r.squared = c(r.squared, lm_summary$r.squared)
        p.value <- c(p.value, anova(lm(log(Predator.mass)~log(Prey.mass), data = type))$'Pr(>F)'[1])
        df <- data.frame(t, l, reg.slope, reg.intercept, r.squared, p.value,f.statistics)
        final_results = rbind(results, df)
  }
}
# writing the output dataframe
colnames(final_results) <- c('Type_of_feeding_interaction', 'predator_lifestage', 'regression_slope', 'regression_intercept', 'R-squared', 'p-value', 'F-statistics')
write.csv(final_results, "../results/PP_Regress_Results.csv")
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
`geom_smooth()` using formula 'y ~ x'
Warning messages:
1: In qt((1 - level)/2, df) : NaNs produced
2: In max(ids, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf
Warning message:
In anova.lm(lm(log(Predator.mass) ~ log(Prey.mass), data = type)) :
  ANOVA F-tests on an essentially perfect fit are unreliable

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:

**********************************************************************
#!/usr/bin/env Rscript

# loading the packages
library(tools)

# loading data from the command line
argv <- commandArgs(trailingOnly = TRUE)
treedata <- read.csv(paste("../data/", argv[1], sep = ""))

TreeHeight <- function(degrees, distance) {

    radians <- degrees * pi / 180
    height <- distance * tan(radians)

    return(height)
}

for (Species in treedata) {
    treehgt <- TreeHeight(treedata$Angle.degrees, treedata$Distance.m)
    return(treehgt)
} 

## add the column of height to the data
treedata$Tree.Height.m <- treehgt

## select the first two rows of data
height_selected <- treedata[1:2,]
height_selected$Input_Name <- argv[1]

## saving the output file
output <- basename(file_path_sans_ext(argv[1]))
write.csv(height_selected, file = paste("../results/", output, "_treeheights.csv", sep = ""))
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in file(file, "rt") : cannot open the connection
Calls: read.csv -> read.table -> file
In addition: Warning message:
In file(file, "rt") :
  cannot open file '../data/NA': No such file or directory
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list = ls())

stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100)
{

  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix

  N[1, ] <- p0

  for (pop in 1:length(p0)) { #loop through the populations

    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)

}

# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 

stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2, numyears = 100){
  # Initialisation
  N <- matrix(NA, numyears, length(p0))
  N[1, ] <- p0

  # Defining the function for looping through the years
  loop_years <- function(x){
    for (yr in 2:numyears){
      x[yr] <- x[yr-1] * exp(r * (1 - x[yr - 1] / K) + rnorm(1, 0, sigma))
    }
    return(x)
  }
  # Vectorising through the columns, which is the population
  N <- apply(N, 2, loop_years)
  
  return(N)
}


print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))
**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.220   0.018   0.237 

**********************************************************************

Code ran without errors

Time consumed = 0.44135s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
# fix(MyData) #you can also do this
# fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package
require(tidyverse)

# ?melt #check out the melt function
######### Changed the melt() funtion to gather() funtion ############

MyWrangledData <- gather(TempData, key = "Species", value = "Count", -c(Cultivation, Block, Plot, Quadrat))

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

require(tidyverse)

tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 

MyWrangledData <- dplyr::as_tibble(MyWrangledData) 
MyWrangledData

MyWrangledData <- as_tibble(MyWrangledData) 
class(MyWrangledData)
glimpse(MyWrangledData) #like str(), but nicer!
filter(MyWrangledData, Count>100) #like subset(), but nicer!

slice(MyWrangledData, 10:15) # Look at a particular range of data rows

MyWrangledData %>%
    group_by(Species) %>%
        summarise(avg = mean(Count))

aggregate(MyWrangledData$Count, list(MyWrangledData$Species), FUN=mean) 



**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: reshape2
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
NoPreallocFun <- function(x) {
    a <- vector()
    for (i in 1:x) {
        a <- c(a, i)
        print(a)
        print(object.size(a))
    }
}
system.time(NoPreallocFun(1000))

PreallocFun <- function(x) {
    a <- rep(NA, x)
    for (i in 1:x) {
        a[i] <- i
        print(a)
        print(object.size(a))
    }
}
system.time(PreallocFun(1000))
**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
56 bytes
[1] 1 2
56 bytes
[1] 1 2 3
64 bytes
[1] 1 2 3 4
64 bytes
[1] 1 2 3 4 5
80 bytes
[1] 1 2 3 4 5 6
80 bytes
[1] 1 2 3 4 5 6 7
80 bytes
[1] 1 2 3 4 5 6 7 8
80 bytes
[1] 1 2 3 4 5 6 7 8 9
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10 11
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10 11 12
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13
112 bytes
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14
112 bytes
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 1
**********************************************************************

Code ran without errors

Time consumed = 1.95154s

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************
i <- 0 #initialize i
    while (i < Inf){
        if (i == 10){
            break
        } else {
            cat("i equals ", i, " \n")
            i <- i + 1
        }
    }
**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.22684s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:

**********************************************************************
#!/bin/sh
# Author: Xuan Wang xuan.wang22@imperial.ac.uk
# Date: 11 Dec 2022
# Description: This script runs both the get_TreeHeight files for R and python.

# Testing of R file
echo "R script started."
Rscript get_TreeHeight.R trees.csv
echo "R script done!"

# Testing of python file
echo "Python script started."
ipython3 get_TreeHeight.py trees.csv
echo "Python script done!"
**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 


**********************************************************************
R script started.
R script done!
Python script started.
[22;0t]0;IPython: Week3/codePython script done!

**********************************************************************

Code ran without errors

Time consumed = 0.96854s

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
# fix(MyData) #you can also do this
# fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

# ?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

require(tidyverse)

tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 

MyWrangledData <- dplyr::as_tibble(MyWrangledData) 
MyWrangledData

MyWrangledData <- as_tibble(MyWrangledData) 
class(MyWrangledData)
glimpse(MyWrangledData) #like str(), but nicer!
filter(MyWrangledData, Count>100) #like subset(), but nicer!

slice(MyWrangledData, 10:15) # Look at a particular range of data rows

MyWrangledData %>%
    group_by(Species) %>%
        summarise(avg = mean(Count))

aggregate(MyWrangledData$Count, list(MyWrangledData$Species), FUN=mean) 



**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: reshape2
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file Florida.tex...

File contents are:

**********************************************************************
\documentclass[11pt, oneside]{article}
\usepackage{geometry}
\geometry{a4paper} 
\usepackage{graphicx}
\usepackage{amssymb}


\title{Is Florida getting warmer?}
\author{Xuan Wang}
\date{Oct 2022}

\begin{document}
\maketitle


\section{Results}
\begin{center}
\includegraphics[scale = 0.7]{../data/Floridaplot.pdf}
\end{center}
\section{Interpretation}
To ensure the variables are independent, a permutation analysis is conducted by randomly reshuffling the temperatures and calculate the coefficients. The distribution of the calculated coefficients are shown in the results graph, and is compared to the original correlation coefficient, which is shown to be approximately 0.533.
\bigbreak
\noindent According to our result, the p-value is 0 since there is no random correlation coefficient detected which is greater than the observed value, 0.533. It is also noticeable that the original correlation coefficient is much larger than the maximum value from the distribution. This indicates a strong evidence to reject the null hypothesis of no significant correlation between the temperature and year. In this case, we can conclude that the temperature in Florida is correlated with the year.

\end{document}  

**********************************************************************

Testing Florida.tex...

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
## loading data
treedata <- read.csv("../data/trees.csv", header = TRUE)

TreeHeight <- function(degrees, distance) {

    radians <- degrees * pi / 180
    height <- distance * tan(radians)

    return(height)
}

for (Species in treedata) {
    print(paste("Tree height of ", treedata$Species, " is: ", TreeHeight(treedata$Angle.degrees, treedata$Distance.m)))
    treehgt = TreeHeight(treedata$Angle.degrees, treedata$Distance.m)
    return(treehgt)
} 

## add the column of height to the data
treedata$Tree.Height.m <- treehgt

## select the first two rows of data
height_selected <- treedata[1:2,]

## saving the output file
write.csv(height_selected, "../results/TreeHts.csv")
**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************
  [1] "Tree height of  Populus tremula  is:  27.8021161438536"             
  [2] "Tree height of  Quercus robur  is:  45.2460250644405"               
  [3] "Tree height of  Ginkgo biloba  is:  14.6654828109493"               
  [4] "Tree height of  Fraxinus excelsior  is:  14.9341751666304"          
  [5] "Tree height of  Betula pendula  is:  35.9703591412599"              
  [6] "Tree height of  Betula pendula  is:  32.4102133664874"              
  [7] "Tree height of  Populus tremula  is:  
**********************************************************************

Code ran without errors

Time consumed = 0.20784s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names=FALSE) # ignore column names
**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Warning message:
In write.table(MyData[1, ], file = "../results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M) {
    Dimensions <- dim(M)
    Tot <- 0
    for (i in 1:Dimensions[1]) {
        for (j in 1:Dimensions[2]) {
            Tot <- Tot + M[i,j]
        }
    }
    return (Tot)
}

print("Using loops, the time taken is:")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is: ")
print(system.time(sum(M)))


**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.068   0.000   0.068 
[1] "Using the in-built vectorized function, the time taken is: "
   user  system elapsed 
  0.001   0.000   0.000 

**********************************************************************

Code ran without errors

Time consumed = 0.32160s

======================================================================
======================================================================
Finished running scripts

Ran into 13 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 98.5

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!